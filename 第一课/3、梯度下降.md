# 梯度下降

对于 $J(\omega,b)$ ,需要设计一个算法，来帮我们系统的找到它的最小值。现在，我用 $\omega$ 的更新为例说明这件事情。首先，需要取 $J(\omega,b)$ 的偏导数

$$
  J_{\omega} = \frac{\partial J(\omega,b)}{\partial \omega}
$$

这个偏导数可以帮助我们判断，需要增加 $\omega$ 还是减少 $\omega$ 。如果 $J_{\omega} > 0$ ,那么说明增加 $\omega$ 会增加 $J(\omega,b)$ ，如果 $J_{\omega} > 0$ ，需要减小 $\omega$  ,反过来也成立。于是有

$$
  \omega_{new} = \omega_{old} - \alpha J_{\omega} 
$$

其中， $\alpha$ 为学习率，可以控制 $\omega$ 变化的速度，合适的学习率设置对于机器学习至关重要。可以采取同样的方法更新所有的参数。梯度下降可以拓展至高纬空间。

# 特征缩放
